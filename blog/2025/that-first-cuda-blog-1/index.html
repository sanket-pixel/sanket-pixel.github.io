<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>That First CUDA Blog I Needed | Sanket Shah</title>
    <meta name="author" content="Sanket R. Shah">
    <meta name="description" content="Learning the ABCs of CUDA">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://sanket-pixel.github.io//blog/2025/that-first-cuda-blog-1/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2Z5HX2M1E"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-J2Z5HX2M1E');
  </script>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Sanket Shah</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">That First CUDA Blog I Needed</h1>
    <p class="post-meta">May 31, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/nvidia">
          <i class="fas fa-hashtag fa-sm"></i> nvidia</a>  
          <a href="/blog/tag/cuda">
          <i class="fas fa-hashtag fa-sm"></i> cuda</a>  
          
        ·  
        <a href="/blog/category/cuda">
          <i class="fas fa-tag fa-sm"></i> cuda</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <h4 id="your-code-is-powerful-but-what-if-you-could-multiply-that-power-by-thousands-this-blog-is-your-invitation-to-unlock-a-completely-new-dimension-of-computing-the-world-of-gpus-well-bypass-the-overwhelming-technical-jargon-and-dense-documentation-offering-the-clarity-and-right-starting-point-you-need-to-truly-grasp-parallel-thinking-this-is-the-plain-language-guide-i-longed-for-when-i-began-explaining-not-just-how-to-write-cuda-but-the-fundamental-principles-that-make-it-tick-whether-youre-aiming-for-faster-ai-robust-system-performance-or-just-curious-about-what-lies-beyond-sequential-code-welcome-lets-embark-on-this-journey-to-parallel-mastery">Your code is powerful, but what if you could multiply that power by thousands? This blog is your invitation to unlock a completely new dimension of computing: the world of GPUs. We’ll bypass the overwhelming technical jargon and dense documentation, offering the clarity and right starting point you need to truly grasp parallel thinking. This is the plain-language guide I longed for when I began, explaining not just how to write CUDA, but the fundamental principles that make it tick. Whether you’re aiming for faster AI, robust system performance, or just curious about what lies beyond sequential code, welcome. Let’s embark on this journey to parallel mastery.</h4>

<p><br></p>
<div style="width: 80%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/kindergarten-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/kindergarten-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/kindergarten-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/kindergarten.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="latency compare" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
   Part 1 : Starting with the ABCs of CUDA
</div>
</div>

<p>A new revolution is unfolding before our eyes: AI isn’t a distant dream anymore but it’s here, reshaping everything from art to healthcare. At the heart of this transformation lies the GPU, a powerhouse that can juggle thousands of tasks simultaneously and make ideas that once lived in science fiction become real. If CPUs are our trusty multi-tools, GPUs are the industrial engines that crank out massive workloads in parallel. And to talk to these engines, we use CUDA, a simple yet powerful language that lets us translate our ideas into blazing-fast GPU code.</p>

<p>When I first dove into CUDA, there wasn’t a single blog post that walked me through everything I needed: the mindset shift, the basic kernels, the data wrangling, and finally a real-world example. That’s exactly why I wrote “That First CUDA Blog I Needed.” I wanted something personal, something that says, “I’ve been there, I felt the confusion, and here’s a friendly guide to help you leap over those hurdles.”</p>

<p>This series is broken into three parts:</p>

<h5 id="part-1-foundations-of-gpu-thinking"><a href="/blog/2025/that-first-cuda-blog-1">Part 1: Foundations of GPU Thinking</a></h5>
<p><a href="/blog/2025/that-first-cuda-blog-1#1-the-paradigm-shift-from-cpu-to-gpu-world">1. The Paradigm Shift from CPU to GPU World</a>   <br>
<a href="/blog/2025/that-first-cuda-blog-1#2-groundwork-what-cuda-assumes-you-know">2. Groundwork: What CUDA Assumes You Know</a><br>
<a href="/blog/2025/that-first-cuda-blog-1/#3-your-first-cuda-kernel-hello-world">3. Your First CUDA Kernel: Hello World!</a></p>

<h5 id="part-2-building-blocks-of-parallelism"><a href="/blog/2025/that-first-cuda-blog-2">Part 2: Building Blocks of Parallelism</a></h5>
<p><a href="/blog/2025/that-first-cuda-blog-2#4-thread-organization-in-cuda">4. Thread Organization in CUDA</a><br>
<a href="/blog/2025/that-first-cuda-blog-2#5-managing-data-from-cpu-to-gpu-and-back">5. Managing Data: From CPU to GPU and Back</a></p>

<h5 id="part-3-a-real-world-cuda-project"><a href="/blog/2025/that-first-cuda-blog-3">Part 3: A Real-World CUDA Project</a></h5>
<p><a href="/blog/2025/that-first-cuda-blog-3#6-your-first-real-cuda-example-grayscale-conversion">6. Your First Real CUDA Example: Grayscale Conversion</a><br>
<a href="/blog/2025/that-first-cuda-blog-3#7-common-pitfalls-when-getting-started">7. Common Pitfalls When Getting Started</a><br>
<a href="/blog/2025/that-first-cuda-blog-3#8-thats-a-wrap-now-youre-cuda-capable">8. That’s a Wrap — Now You’re CUDA-Capable</a></p>

<p>By the end of this journey, I hope you’ll feel as excited (and a little humbled) as I did when my first GPU code ran without crashing. You won’t just have written some kernels—you’ll have joined a community of people who are building the future, one parallel thread at a time. Welcome, and let’s get started on what really matters.</p>

<blockquote>
  <p>All the code related to this blog series, accompanying each step of your CUDA learning journey, can be found on GitHub at: <a href="https://github.com/sanket-pixel/blog_code/tree/main/8_that_first_cuda_blog" rel="external nofollow noopener" target="_blank">https://github.com/sanket-pixel/blog_code/tree/main/8_that_first_cuda_blog</a>.</p>
</blockquote>

<h3 id="1-the-paradigm-shift-from-cpu-to-gpu-world"><strong>1. The paradigm shift from CPU to GPU World</strong></h3>

<p>Programming for the GPU isn’t just about speed — it’s about scale. A GPU isn’t a faster version of your CPU. It’s a completely different machine built with a different philosophy: <strong>do many small things all at once, not one big thing faster.</strong></p>

<p>On the CPU, you’re the expert chef in the kitchen, handling every dish end-to-end with precision. On the GPU, you’re the head of a large team of cooks, each chopping, frying, or seasoning in parallel. The job gets done faster not because each cook is faster than you — but because you’re not doing it alone.</p>

<p>This mental shift is the first and most important leap. When we write CPU code, we think step by step: first do this, then that, then the next. But with GPUs, you have to learn to think like a parallelist: <em>How can I break this task into a thousand identical pieces that can run simultaneously, without waiting on each other?</em></p>

<p>That’s the real challenge for most beginners — not the CUDA syntax, not the memory allocation APIs, but this fundamental change in mindset. The GPU model asks:
<strong>“If I gave you 10,000 workers, each capable of doing the same thing — how would you structure the task?”</strong></p>

<p>CUDA doesn’t want you to program the solution to your problem.<br>
It wants you to program the solution to a small piece of your problem — and let the GPU handle the rest.</p>

<p>The good news? Once this clicks, everything else starts to make sense.<br>
The bad news? You’ll never look at your CPU code the same way again.</p>

<p><br></p>
<div style="width: 80%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/cpu_vs_gpu-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/cpu_vs_gpu-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/cpu_vs_gpu-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/cpu_vs_gpu.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="cpugpu" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
   CPU: The lone chef. GPU: The parallel kitchen team.
</div>
</div>

<p>Let’s say we want to multiply each number in an array by 2.</p>

<p>On the CPU, you would think sequentially as shown below :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="k">from</span> <span class="mi">0</span> <span class="n">to</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
</code></pre></div></div>

<p>Here, you think like a <strong>single worker</strong> walking through the entire list, <strong>one element at a time</strong>.<br>
While on the GPU you must think of processing in parallel as shown below :</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">function</span> <span class="nf">worker</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">launch</span> <span class="n">N</span> <span class="n">workers</span><span class="p">:</span>
    <span class="n">each</span> <span class="n">runs</span> <span class="nf">worker</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">with</span> <span class="n">its</span> <span class="n">own</span> <span class="n">i</span>
</code></pre></div></div>
<p>Instead of one worker doing the whole loop, you write code for just <strong>one worker</strong>, and let <strong>thousands of them</strong> each handle their own <code class="language-plaintext highlighter-rouge">i</code> independently.
You’re no longer in control of the whole process—you’re only describing what one tiny part of the system should do. This mental shift—from controlling a loop to writing instructions for an army of workers—is what makes parallel thinking hard at first.</p>

<h3 id="2-groundwork-what-cuda-assumes-you-know"><strong>2. Groundwork: What CUDA Assumes You Know</strong></h3>
<p>If you’ve spent most of your time in languages like Python, JavaScript, or even high-level C++ without touching low-level memory concepts, CUDA will feel different. That’s because CUDA code is almost always written in C or C++, and runs in an environment where you’re much closer to the hardware. Let us understand some core low level programming concepts you should know, before finally writing our first CUDA kernel in the next section.</p>

<h5 id="21-pointers--variables-that-point-to-other-variable"><strong>2.1 Pointers : Variables that point to other Variable</strong></h5>
<p>A pointer is a variable that <strong>stores the memory address of another variable</strong>. In Python, you deal with lists and objects without thinking about where they live in memory. But in CUDA (and C/C++), you often work with memory addresses directly. In this fighure below, <code class="language-plaintext highlighter-rouge">x</code> is an integer variable that holds the value <code class="language-plaintext highlighter-rouge">10</code>, and it lives at memory address <code class="language-plaintext highlighter-rouge">0x1234</code>.
<br></p>
<div style="width: 60%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/pointer-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/pointer-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/pointer-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/pointer.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="pointer" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
   Illustration of a pointer in C++
</div>
</div>

<p>The pointer <code class="language-plaintext highlighter-rouge">ptr</code> is declared to hold the address of an integer. When we assign it <code class="language-plaintext highlighter-rouge">&amp;x</code>, we’re storing the address of <code class="language-plaintext highlighter-rouge">x</code> in <code class="language-plaintext highlighter-rouge">ptr</code>. So now <code class="language-plaintext highlighter-rouge">ptr</code> contains <code class="language-plaintext highlighter-rouge">0x1234</code> — it points to <code class="language-plaintext highlighter-rouge">x</code>.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
<span class="kt">int</span><span class="o">*</span> <span class="n">ptr</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">x</span><span class="p">;</span>  <span class="c1">// ptr now holds the memory address of x (e.g., 0x1234)</span>
</code></pre></div></div>
<p>The pointer itself lives at a different memory location, say <code class="language-plaintext highlighter-rouge">0x1550</code>. If we access <code class="language-plaintext highlighter-rouge">*ptr</code>, we get the value stored at the address it points to — in this case, <code class="language-plaintext highlighter-rouge">10</code>. And if we use <code class="language-plaintext highlighter-rouge">&amp;ptr</code>, we get the address where the pointer itself is stored — <code class="language-plaintext highlighter-rouge">0x1550</code>.</p>

<h5 id="22-functions--parameter-passing-by-value-vs-reference"><strong>2.2 Functions : Parameter Passing by Value vs. Reference</strong></h5>
<p>A function is a reusable block of code that performs a specific task and can take inputs (parameters) and return outputs — just like how functions work in Python.
In C, when you <strong>pass by value</strong>, the function gets a <strong>copy of the data</strong>. When you <strong>pass by reference</strong> (using a pointer), the function gets access to the <strong>original</strong>, so it can modify it.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">modify</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">);</span>     <span class="c1">// gets a copy of x</span>
<span class="kt">void</span> <span class="nf">modify</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">x</span><span class="p">);</span>    <span class="c1">// gets the original x via address</span>
</code></pre></div></div>

<p>Passing by value is like giving someone a photocopy of a document, while passing by reference is like giving them the original paper to make changes on.</p>

<h5 id="23-arrays-and-memory-layout"><strong>2.3 Arrays and Memory Layout</strong></h5>
<p>In high-level languages, arrays feel like magical lists, but under the hood, an array is just a block of memory where all elements sit <strong>side by side</strong>.
This figure below illustrates how array elements, like integers, are stored contiguously in memory. Each element occupies a specific block of memory, and for <code class="language-plaintext highlighter-rouge">int</code> types, these blocks are typically separated by <code class="language-plaintext highlighter-rouge">4 bytes</code>, allowing precise calculation of each element’s address from the array’s start.</p>
<div style="width: 70%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/array.svg-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/array.svg-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/array.svg-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/array.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="array" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
Memory layout of a 4-element integer array with 4-byte spacing.
</div>
</div>

<p>Because array elements are stored contiguously in memory, a pointer to the first element can be used to access any other element using pointer arithmetic. If <code class="language-plaintext highlighter-rouge">ptr</code> points to the start of the array, <code class="language-plaintext highlighter-rouge">ptr + i</code> moves the pointer <code class="language-plaintext highlighter-rouge">i</code> elements forward (not bytes — it accounts for the size of each element).
For example, to increment the third element (index 2):</p>
<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">arr</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">};</span>
<span class="kt">int</span> <span class="o">*</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">arr</span><span class="p">;</span>

<span class="n">ptr</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">ptr</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// arr[2] becomes 4</span>
</code></pre></div></div>
<p>Here, <code class="language-plaintext highlighter-rouge">ptr[2]</code> accesses the third element of the array, just like <code class="language-plaintext highlighter-rouge">arr[2]</code> would. This highlights the deep connection between arrays and pointers in C.</p>

<h5 id="24-2d-arrays-and-memory-layout"><strong>2.4 2D Arrays and Memory Layout</strong></h5>
<p>In C/C++, 2D arrays are stored in row-major order — meaning all elements of the first row come first in memory, followed by the second row, and so on. So even though we access elements using two indices (row and column), in memory it’s just a flat, contiguous block. This is illustrated in the figure below.</p>
<div style="width: 90%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/matrix.svg-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/matrix.svg-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/matrix.svg-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/matrix.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="matrix" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
2D matrices, like this (3,4) example, are arranged row-major and stored contiguously in memory.
</div>
</div>

<p>You can calculate the memory index of any element using:</p>
<blockquote>
  <p><code class="language-plaintext highlighter-rouge">index = row * num_columns + col</code></p>
</blockquote>

<p>In the code below, <code class="language-plaintext highlighter-rouge">ptr[9]</code> accesses the same memory location as <code class="language-plaintext highlighter-rouge">matrix[2][1]</code>, because it is the 10th element in the row-major flattened memory layout (starting from index 0).</p>
<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">matrix</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">},</span>
    <span class="p">{</span><span class="mi">11</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">},</span>
    <span class="p">{</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">}</span>
<span class="p">};</span>
<span class="kt">int</span> <span class="o">*</span><span class="n">ptr</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">r</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="kt">int</span> <span class="n">num_columns</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
<span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">num_columns</span> <span class="o">+</span> <span class="n">c</span><span class="p">;</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"%d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">ptr</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>  <span class="c1">// Output: 3</span>
</code></pre></div></div>

<h5 id="25-stack-vs-heap-memory"><strong>2.5 Stack vs Heap Memory</strong></h5>
<p>This is often overlooked but important. In C/C++, small, fixed-size variables (like integers or small structs) are stored on the <strong>stack</strong> — a <strong>fast</strong>, temporary memory area that <strong>automatically manages variable lifetime</strong>.</p>

<p>In contrast, <strong>dynamically allocated</strong> memory (such as arrays created with <code class="language-plaintext highlighter-rouge">malloc</code> or <code class="language-plaintext highlighter-rouge">new</code>) lives on the <strong>heap</strong>, which is larger but slower and must be <strong>manually managed</strong> (allocated and freed).</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>                                 <span class="c1">// Stored on the stack</span>
<span class="kt">int</span><span class="o">*</span> <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="nf">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>  <span class="c1">// Allocated on the heap</span>
</code></pre></div></div>

<p>We have now laid the essential groundwork of concepts—pointers, functions, memory layout, stack, and heap—on which CUDA programming is built.
Understanding these basics will make your journey into parallel programming much smoother.</p>

<h4 id="3-your-first-cuda-kernel-hello-world"><strong>3. Your First CUDA Kernel: Hello World!</strong></h4>

<p>Now that we have a solid understanding of the foundational concepts, let’s dive into writing our very first CUDA kernel. The goal here isn’t complex computation, but to bridge the gap between CPU-style sequential thinking and GPU-style parallel execution, and to see your GPU actually <em>do something</em>.</p>

<p>A good way to learn something new, is to begin from something you already know and then connect the dots. Let us first look at a simple <strong>Hello World</strong> program in C++.</p>
<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>To execute this program on your machine, follow the following steps :</p>

<ol>
  <li>Clone the <a href="https://github.com/sanket-pixel/blog_code" rel="external nofollow noopener" target="_blank">repository</a> that stores the code associated with my blogs :
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>git clone https://github.com/sanket-pixel/blog_code
<span class="nb">cd </span>blog_code
</code></pre></div>    </div>
  </li>
  <li>Navigate to the directory <strong>8_that_first_cuda_blog/1_hello_world</strong>
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>8_that_first_cuda_blog/1_hello_world
</code></pre></div>    </div>
  </li>
  <li>Compile the program using the following command
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>g++ hello_world_cpu.cpp <span class="nt">-o</span> hello_world_cpu
</code></pre></div>    </div>
  </li>
  <li>This will create an executable <code class="language-plaintext highlighter-rouge">hello_world</code> in this directory. Execute it using
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>./hello_world_cpu
</code></pre></div>    </div>
  </li>
</ol>

<p>This should print <code class="language-plaintext highlighter-rouge">Hello World from CPU!</code> in the terminal, as expected. Here, the g++ compiler translates your C++ code into instructions that the CPU can execute directly.</p>

<p>Finally, let’s write our first CUDA kernel that performs the same task — printing “Hello World” — but this time the message will come from the GPU.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="c1">  // This include statement allows us to use cuda library in our code</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World from CPU!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="n">gpu_hello_world</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>To execute this program on your machine, follow the following steps :</p>

<ol>
  <li>Navigate to the directory <code class="language-plaintext highlighter-rouge">8_that_first_cuda_blog/1_hello_world</code>
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>8_that_first_cuda_blog/1_hello_world
</code></pre></div>    </div>
  </li>
  <li>Compile the program using the following command
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>nvcc hello_world_gpu.cu <span class="nt">-o</span> hello_world_gpu
</code></pre></div>    </div>
  </li>
  <li>This will create an executable hello_world in this directory. Execute it using
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>./hello_world_gpu
</code></pre></div>    </div>
  </li>
  <li>The output should be the following
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>Hello World from CPU!
Hello World from GPU! 
</code></pre></div>    </div>
  </li>
</ol>

<p>Now that we have our first CUDA program running, let us dissect this CUDA program, and understand how it works from first principles. <br></p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The code snippet above is a function that is intended to run on the GPU. <br> 
In the GPU jargon, such a function is called <strong>kernel</strong>. <br></p>

<p>Kernel, specifically, is a special function, that can be invoked from the CPU, but runs only on the GPU.
CPU, is generally referred to as <strong>host</strong> and GPU is referred to as <strong>device</strong>, since the CPU hosts the GPU in some sense.
The <code class="language-plaintext highlighter-rouge">__global__</code> keyword is used to specify that this function is a <strong>kernel</strong>, in that, it can be called from the host but executed on the device.</p>

<p><code class="language-plaintext highlighter-rouge">gpu_hello_world&lt;&lt;&lt;1,1&gt;&gt;&gt;();</code> is a CUDA-specific syntax. We will discuss what <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code> means later in this blog. 
For now it is sufficient to understand that <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>, allocates 1 thread for executing this kernel.</p>

<p>Let us now extend our single thread CUDA Hello World, to run it with 8 threads. We would like the GPU to repeat this same <code class="language-plaintext highlighter-rouge">Hello World from GPU</code> operation 8 times. Just one small change in our original code will make this happen.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World from CPU!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="c1">// HERE , we replace &lt;&lt;&lt;1,1&gt;&gt;&gt; with &lt;&lt;&lt;1,8&gt;&gt;&gt;.</span>
  <span class="n">gpu_hello_world</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The output of this code, will be one <code class="language-plaintext highlighter-rouge">Hello World from CPU!</code> and 8 <code class="language-plaintext highlighter-rouge">Hello World from GPU!</code>s. 
The main change as explained in the comment above the kernel code is replace <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code> with <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code>, which essentially
means launching the same kernel with 8 threads. The GPU runs 8 “print Hello World” operations in parallel.</p>

<p>We will understand what <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code> exactly means in absolute detail, but at this point, it is sufficient to understand that <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>
launches one thread and <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code> launches 8 threads in parallel.</p>

<p>In summary, in this <strong>Hello World</strong> section, we first looked at how to print Hello World using the CPU, followed by the same using the GPU.
The major takeaway from this section is to understand what are kernels in general, and how <em>exactly</em> is a kernel launched from the <strong>host</strong>, to run the same operations in parallel on the <strong>device</strong>.</p>

<p>Up next in <a href="/blog/2025/that-first-cuda-blog-2">Part 2: Building Blocks of Parallelism</a>, we’ll explore the building blocks of parallelism that make CUDA powerful. From thread organization to managing memory across CPU and GPU — it’s where things start to click.</p>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/that-first-cuda-blog-3/">That First CUDA Blog I Needed :Part 3</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/that-first-cuda-blog-2/">That First CUDA Blog I Needed :Part 2</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/hidden-speed-in-shared-memory/">Hidden Speed in CUDA's Shared Memory</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/a-practical-guide-to-quantization/">A practical guide to Quantization</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/down-the-cudamemory-lane/">Down the CudaMemory lane</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Sanket R. Shah. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
