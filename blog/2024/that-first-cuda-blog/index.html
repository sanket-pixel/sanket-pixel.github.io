<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>That First CUDA Blog I Needed | Sanket Shah</title>
    <meta name="author" content="Sanket R. Shah">
    <meta name="description" content="The ideal first blog to start learning CUDA.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://sanket-pixel.github.io//blog/2024/that-first-cuda-blog/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Sanket Shah</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">That First CUDA Blog I Needed</h1>
    <p class="post-meta">October 20, 2024</p>
    <p class="post-tags">
      <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>
        ·  
        <a href="/blog/tag/nvidia">
          <i class="fas fa-hashtag fa-sm"></i> nvidia</a>  
          <a href="/blog/tag/cuda">
          <i class="fas fa-hashtag fa-sm"></i> cuda</a>  
          
        ·  
        <a href="/blog/category/cuda">
          <i class="fas fa-tag fa-sm"></i> cuda</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <h4 id="in-this-blog-were-going-to-dive-into-one-of-the-most-critical-concepts-in-cuda-programming-shared-memory-shared-memory-is-like-the-secret-ingredient-that-can-supercharge-your-gpu-code-while-cudas-global-memory-serves-as-the-main-storage-its-often-slow-to-access-repeatedly-thats-where-shared-memory-comes-in-it-acts-as-a-customizable-fast-access-scratchpad-where-you-can-store-data-that-is-frequently-reused-by-threads-within-the-same-block-helping-you-avoid-costly-memory-transfers-well-explore-how-this-works-why-it-matters-and-how-you-can-use-it-to-make-your-cuda-programs-much-faster">In this blog, we’re going to dive into one of the most critical concepts in CUDA programming: shared memory. Shared memory is like the secret ingredient that can supercharge your GPU code. While CUDA’s global memory serves as the main storage, it’s often slow to access repeatedly. That’s where shared memory comes in. It acts as a customizable, fast-access scratchpad where you can store data that is frequently reused by threads within the same block, helping you avoid costly memory transfers. We’ll explore how this works, why it matters, and how you can use it to make your CUDA programs much faster.</h4>
<p><br></p>

<div style="width: 80%;margin: 0 auto;">
<div class="row">
    <div class="col-sm mt-3 mt-md-0 text-center"> <!-- Add 'text-center' class here -->
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/blog_8/cuda-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/blog_8/cuda-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/blog_8/cuda-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/blog_8/cuda.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="latency compare" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
   Let us begin the CUDA journey, the right way.
</div>
</div>

<!-- ``` ### 0. Prerequisites to learn CUDA``` -->

<h3 id="1-hello-world">1. Hello World</h3>
<p>A good way to learn something new, is to begin from something you already know and then connect the dots. Let us first look at a simple <code class="language-plaintext highlighter-rouge">Hello World</code> program in C++.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>To execute this program on your machine, follow the following steps :</p>

<ol>
  <li>Open a terminal and navigate to the directory containing this <code class="language-plaintext highlighter-rouge">.cpp</code> file.
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> cd that_first_cuda_blog/1_hello_world
</code></pre></div>    </div>
  </li>
  <li>Compile the program using the following command
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> g++ hello_world.cpp <span class="nt">-o</span> hello_world
</code></pre></div>    </div>
  </li>
  <li>This will create an executable <code class="language-plaintext highlighter-rouge">hello_world</code> in this directory. Execute it using
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> ./hello_world
</code></pre></div>    </div>
  </li>
</ol>

<p>This should print <code class="language-plaintext highlighter-rouge">Hello World!</code> in the terminal, as expected. Here, the <strong>g++ compiler</strong> compiles the source code <code class="language-plaintext highlighter-rouge">hello_world.cpp</code> and translates it to machine code, in form of an executable file. 
The CPU then executes this machine code, to print <code class="language-plaintext highlighter-rouge">Hello World!</code> onto the temrinal.</p>

<p>If one intends to execute the same on an NVIDIA GPU, <strong>CUDA</strong> can be used.<br>
CUDA is a programming framework, that allows programmers to talk to NVIDIA GPUs via the CPU.</p>

<p><strong>TODO : TALK HERE ABOUT HOW CUDA HAS PARALLILAZATION USING THREADS</strong></p>

<p>Let us look at simple Hello World example in CUDA.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World from CPU!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="n">gpu_hello_world</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>To execute this program on your machine, follow the following steps :</p>

<ol>
  <li>Open a terminal and navigate to the <code class="language-plaintext highlighter-rouge">1_hello_world</code> directory
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> cd that_first_cuda_blog/1_hello_world
</code></pre></div>    </div>
  </li>
  <li>Compile the program using the following command
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> nvcc hello_world_gpu.cu <span class="nt">-o</span> hello_world_gpu
</code></pre></div>    </div>
  </li>
  <li>This will create an executable <code class="language-plaintext highlighter-rouge">hello_world_gpu</code> in this directory. Execute it using
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> ./hello_world_gpu
</code></pre></div>    </div>
  </li>
  <li>The output should be the following
    <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> Hello World from CPU!
 Hello World from GPU! 
</code></pre></div>    </div>
  </li>
</ol>

<p>Now that we have our first CUDA program running, let us dissect this CUDA program, and understand how it works from first principles. <br></p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The code snippet above is a function that is intended to run on the GPU. <br> 
In the GPU jargon, such a function is called <strong>kernel</strong>. <br></p>

<p>Kernel, specifically, is a special function, that can be invoked from the CPU, but runs only on the GPU.
CPU, is generally referred to as <code class="language-plaintext highlighter-rouge">host</code> and GPU is referred to as <code class="language-plaintext highlighter-rouge">device</code>, since the CPU hosts the GPU in some sense.
The <code class="language-plaintext highlighter-rouge">__global__</code> keyword is used to specify that this function is a <strong>kernel</strong>, in that, it can be called from the host but executed on the device.</p>

<p><code class="language-plaintext highlighter-rouge">gpu_hello_world&lt;&lt;&lt;1,1&gt;&gt;&gt;();</code> is a CUDA-specific syntax. We will discuss what <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code> means later in this blog. 
For now it is sufficient to understand that <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>, allocates 1 thread for executing this kernel.</p>

<p>Let us first understand how this kernel launch works from first principles.</p>

<ol>
  <li>The <code class="language-plaintext highlighter-rouge">host</code> (CPU) executes instructions ( compiled lines of code ), one at a time, sequentially.</li>
  <li>When it reaches the kernel launch instruction (<code class="language-plaintext highlighter-rouge">gpu_hello_world&lt;&lt;&lt;1,1&gt;&gt;&gt;();</code>), the host launches the kernel.
Under the hood, the <strong>CUDA Runtime Library</strong> on the host, places the launch command onto a <strong>CUDA Stream</strong> which a queue mantained 
on the host.  This queue is designed to hold kernel launches, memory transfer requests and other CUDA tasks, to ensure they execute sequentially for the same <strong>CUDA Stream</strong>.
We will dissect  <strong>CUDA Streams</strong> later in this blog.</li>
  <li>The CUDA Runtime, now hands over the launch commands to the <strong>NVIDIA Driver</strong> on the <code class="language-plaintext highlighter-rouge">host</code>, which is responsible for talking to the <code class="language-plaintext highlighter-rouge">device</code> (GPU).</li>
  <li>The <strong>NVIDIA Driver</strong> pushes this launch command to the <strong>command buffer</strong> which is managed by the GPU hardware. This buffer resides on the <code class="language-plaintext highlighter-rouge">device</code> and 
holds the commands to be executed, once sufficient GPU resources are available.</li>
  <li>The GPU, once resources are available, pulls commands from the <strong>command buffer</strong> and starts executing them.</li>
  <li>The <strong>host does not wait for the kernel execution to finish</strong>, and moves on with the next instruction. This execution approach is known as <strong>asynchronous</strong>. In particular, the <code class="language-plaintext highlighter-rouge">host</code> and <code class="language-plaintext highlighter-rouge">device</code> executes independently and simulatenously. When a command is like kernel launch is issued by the host, it does not wait for the command to complete on the <code class="language-plaintext highlighter-rouge">device</code>, but simply moves on to the next instruction, while the <code class="language-plaintext highlighter-rouge">device</code> handles the requested operation in parallel.</li>
</ol>

<p>To unerstand this better, we can change the earlier <code class="language-plaintext highlighter-rouge">hello_world.cu</code> source code, by commenting out <code class="language-plaintext highlighter-rouge">cudaDeviceSynchronize();</code>.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World from CPU!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="n">gpu_hello_world</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="c1">// comment out this line. </span>
  <span class="c1">// Now the host does not wait for the device and moves on.</span>
  <span class="c1">// cudaDeviceSynchronize();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The output of this program will be just as follows :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hello World from CPU!
</code></pre></div></div>

<p>Note, that since we removed <code class="language-plaintext highlighter-rouge">cudaDeviceSynchronize();</code>, the host launches the <code class="language-plaintext highlighter-rouge">gpu_hello_world</code> kernel and moves on to the next instruction. The exection of the host code finishes, even before the <code class="language-plaintext highlighter-rouge">device</code> completes, hence it does not print <code class="language-plaintext highlighter-rouge">Hello World from GPU!</code> onto the output buffer.</p>

<p>Let us now extend our single thread CUDA Hello World, to run it with 8 threads. We would like the GPU to repeat this same “Hello World from GPU” operation 8 times. Just one small change in our original code will make this happen.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpu_hello_world</span><span class="p">(){</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU! </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World from CPU!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="c1">// HERE , we replace &lt;&lt;&lt;1,1&gt;&gt;&gt; with &lt;&lt;&lt;1,8&gt;&gt;&gt;.</span>
  <span class="n">gpu_hello_world</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The output of this code, will be one <code class="language-plaintext highlighter-rouge">Hello World from CPU!</code> and 8 <code class="language-plaintext highlighter-rouge">Hello World from GPU!</code>s. 
The main change as explained in the comment above the kernel code is replace <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code> with <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code>, which essentially
means launching the same kernel with 8 threads. The GPU runs 8 “print Hello World” operations in parallel.</p>

<p>We will understand what <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code> exactly means in absolute detail, but at this point, it is sufficient to understand that <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>
launches one thread and <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,8&gt;&gt;&gt;</code> launches 8 threads in parallel.</p>

<p>In summary, in this <strong>Hello World</strong> section, we first looked at how to print Hello World using the CPU, followed by the same using the GPU.
The major takeaway from this section is to understand what are kernels in general, and how <em>exactly</em> is a kernel launched from the <code class="language-plaintext highlighter-rouge">host</code>, to run the same operations in parallel on the <code class="language-plaintext highlighter-rouge">device</code>.</p>

<!-- TODO : ADD OS Concepts here -->

<h3 id="2-print-square-of-numbers">2. Print Square of Numbers</h3>
<p>The basic foundation is now laid and we will now lay some more foundation on top.
Let us print square of list of integers.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="cp">#define N 5
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">print_square</span><span class="p">(){</span>
  <span class="kt">unsigned</span> <span class="n">id</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"%d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">id</span> <span class="o">*</span> <span class="n">id</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">*</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">print_square</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>


    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/hidden-speed-in-shared-memory-copy/">Hidden Speed in CUDA's Shared Memory</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/a-practical-guide-to-quantization/">A practical guide to Quantization</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/down-the-cudamemory-lane/">Down the CudaMemory lane</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/quantization-explained-like-youre-five/">Quantization explained, like you are five.</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tensorrt-meets-cpp/">TensorRT meets C++</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Sanket R. Shah. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
